{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Hacker News is a social media website where users post and discuss technology related content. Just like on Reddit, users have the ability to upvote their favorite posts to the front page of the website. The more upvotes a post earns, the more views it is likely to attract. There are many different types of posts in Hacker News. In this project, I aim to determine which time of the day sees the most number of comments on average. In addition, I want to find out which of the two classes of publications, **Ask HN** or **Show HN**, receives more comments on average. In submitting **Ask HN** posts, users seek answers to questions from Hacker News community. In submitting **Show HN** posts, users display an interesting project or product to the forum.  \n",
    "\n",
    "## Data \n",
    "\n",
    "The data set I will be working on comes from Dataquest. It is a modified version of the original [source](https://www.kaggle.com/hacker-news/hacker-news-posts). It contains approximately 20,000 observations on posts that have at least one comment.\n",
    "\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "#observe first five rows\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform analysis on the data, I will remove column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "\n",
    "#remove headers\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "\n",
    "#verify that headers are removed\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that the column headers have been extracted from the *hn* list, I can  filter the posts by **Ask HN** and **Show HN** titles and arrange them into their own lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "#create empty lists for each type of post\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"): \n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    total_ask_comments = total_ask_comments + int(post[4])\n",
    "avg_ask_comments  = total_ask_comments / len(ask_posts)\n",
    "print (avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0 \n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments = total_show_comments + int(post [4])\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, ask posts receive 14 comments and show posts receive 10 comments. Since ask posts generate more user participation than show posts do, I would like to learn if ask posts submitted at a certain time during the day are more likely to get comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    result_list.append([post[6],int(post[4])])\n",
    "\n",
    "counts_by_hour = {}\n",
    "\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    date = dt.datetime.strptime(date,\"%m/%d/%Y %H:%M\")\n",
    "    date_obj = date.time()\n",
    "    hour = date_obj.strftime('%H')\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "    \n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['10', 13.440677966101696],\n",
       " ['15', 38.5948275862069],\n",
       " ['06', 9.022727272727273],\n",
       " ['02', 23.810344827586206],\n",
       " ['23', 7.985294117647059],\n",
       " ['20', 21.525],\n",
       " ['08', 10.25],\n",
       " ['16', 16.796296296296298],\n",
       " ['01', 11.383333333333333],\n",
       " ['14', 13.233644859813085],\n",
       " ['00', 8.127272727272727],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['21', 16.009174311926607],\n",
       " ['11', 11.051724137931034],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['17', 11.46],\n",
       " ['04', 7.170212765957447],\n",
       " ['22', 6.746478873239437],\n",
       " ['12', 9.41095890410959],\n",
       " ['07', 7.852941176470588],\n",
       " ['13', 14.741176470588234]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hour[1],hour[0]])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for average, hour in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(hour,\"%H\")\n",
    "    hour = hour.strftime('%H:%M')\n",
    "    output = \"{}: {num:.2f} average comments per post.\".format(hour,num = average)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask posts see the highest number of comments per post made on average at 15:00 US Eastern time. The number of comments made at 3 p.m. is substantially higher than the number of comments received per post at 2 a.m. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
